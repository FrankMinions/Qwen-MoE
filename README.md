# Qwen-MoE

Based on [Qwen-7B](https://github.com/QwenLM/Qwen), I build a mixture of experts (MoE) named Qwen-MoE with 36B size which is shown as below.
<p>
    <img src="figures/qwen_moe.png" width="1000"/>
<p>
